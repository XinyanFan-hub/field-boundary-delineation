{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZeSZWtxITOh"
   },
   "source": [
    "# Field boundary mapping in small scale farming using multi-resolution satellite data\n",
    "\n",
    "The code was developed within a project funded by FAO, aiming at developing automatic workflows for mapping rice field boundaries in small-scale farming, using deep learning neural networks and advanced image processing. We conducted case studies in Cambodia and Vietnam, where rice paddy occupies a large portion of the agricultural area. We are facing two major challenges in the targeted research areas: (1) the lack of reference data, and (2) the fragmented agricultural areas characterized by very small fields (i.e., less than 1 ha). To overcome them, we used a convolutional deep learning U-Net network, able to achieve accurate segmentation result even with few training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16406,
     "status": "ok",
     "timestamp": 1647955885837,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "xFDIcczJKJEZ",
    "outputId": "2916e053-104b-4955-ae1a-9adef403d207"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-08 15:20:58.855312: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/lib/jvm/java-11-openjdk-amd64/lib/server:/opt/hadoop/lib/native:/usr/local/lib/R/lib:/usr/local/grass82/lib\n",
      "2022-10-08 15:20:58.855328: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import typing\n",
    "from osgeo import gdal\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from skimage import exposure\n",
    "import shutil\n",
    "\n",
    "# Install keras-unet library for python\n",
    "%pip install git+https://github.com/karolzak/keras-unet\n",
    "\n",
    "BASE_PATH = \"/home/jovyan/private/Agricultural_Field_Boundary\"\n",
    "INPUT_PATH = BASE_PATH + \"/Training_dataset/\"\n",
    "NETWORK_PATH = BASE_PATH + \"/Networks\"\n",
    "IMAGE_PATH = \"/Original\"\n",
    "LABEL_PATH = \"/Classified\"\n",
    "PREDICTION_PATH = BASE_PATH + \"/Prediction/\"\n",
    "\n",
    "# INCLUDE_FOLDERS = [\"Flevoland\", \"Friesland\", \"Gelderland\", \"Limburg\", \"Overijssel\", \"Zeeland\", \"Zuid-Holland\",\"Vietnam\",\"Cambodia\"]\n",
    "INCLUDE_FOLDERS = [\"Vietnam\"]\n",
    "LEGEND = {\n",
    "    1: 'Other',\n",
    "    2: 'Field Boundary'\n",
    "}\n",
    "\n",
    "\n",
    "# To assess the accuracy you have to define the networks UUID and name here\n",
    "NETWORK_UUID = \"219dc590-4674-11ed-baed-02420a0001e2\"\n",
    "\n",
    "# Allowed Values:\n",
    "#   * FCNDK3\n",
    "#   * FCNDK4\n",
    "#   * FCNDK5\n",
    "#   * FCNDK6\n",
    "#   * UNet2\n",
    "#   * UNet3\n",
    "NETWORK_NAME = \"UNet5\"\n",
    "\n",
    "\n",
    "# To compile the model, also the optimizer has to be defined\n",
    "NETWORK_OPTIMIZER = \"Adam\"\n",
    "\n",
    "# Ensure you use the same optimizer parameters as in the training run\n",
    "SGD_LEARNING_RATE = 0.0015\n",
    "SGD_MOMENTUM = 0.9\n",
    "ADAM_LEARNING_RATE = 0.001\n",
    "ADAM_BETA_1 = 0.9\n",
    "ADAM_BETA_2 = 0.999\n",
    "ADAM_EPSILON= 1e-07\n",
    "\n",
    "# Note: .ipynb_checkpoints are generated from the notebook interface\n",
    "# when removing/adding image samples manually. They should be deleted,\n",
    "# otherwise the Kernel will be died and forced to restart\n",
    "for folder in INCLUDE_FOLDERS:\n",
    "    original = INPUT_PATH + folder + IMAGE_PATH\n",
    "    classified = INPUT_PATH + folder + LABEL_PATH\n",
    "    if os.path.exists(f\"{original}/.ipynb_checkpoints\"):\n",
    "        shutil.rmtree(f\"{original}/.ipynb_checkpoints\")\n",
    "    if os.path.exists(f\"{classified}/.ipynb_checkpoints\"):\n",
    "        shutil.rmtree(f\"{classified}/.ipynb_checkpoints\")\n",
    "\n",
    "        \n",
    "# Remark: All information in here could have been loaded from the training\n",
    "#         configuration file as well. However, we missed the chance to export\n",
    "#         the configuration as a machine readable type, e.g. JSON.\n",
    "#         Thus, we did not pass the config from the readme manually but set the\n",
    "#         parameters manually in here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3367,
     "status": "ok",
     "timestamp": 1647955889199,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "sB6fZzP744dc"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Prerequisites for the network\n",
    "#\n",
    "# Includes a few helper functions which will be used to create and\n",
    "# evaluate the network, the training and the accuracy.\n",
    "# ################################################################\n",
    "\n",
    "import imp, h5py\n",
    "import dill, pickle\n",
    "import uuid\n",
    "imp.reload(h5py)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "sess = K.get_session()\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "\n",
    "# Tensorflow configuration\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "\n",
    "\n",
    "# ################################################################\n",
    "# Helper functions - import/export of network\n",
    "#\n",
    "# These two functions help to export the network and import it.\n",
    "# That allows to skip the training at a later stage.\n",
    "# ################################################################\n",
    "\n",
    "class ModelHistory:\n",
    "    \"\"\"Just a small container class to hold relevant information of a trained\n",
    "    model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, uuid, name, model, history, readme):\n",
    "        \"\"\"Create a new instance of this class\n",
    "        :param uuid: A unique identifier of the network\n",
    "        :param name: The networks name\n",
    "        :param model: The pretrained model\n",
    "        :param history: The training history of the model\n",
    "        :param readme: A small readme with a summary of training parameters\n",
    "        \"\"\"\n",
    "        self.uuid = uuid\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.history = history\n",
    "        self.readme = readme\n",
    "\n",
    "\n",
    "def get_file_names(uuid, name):\n",
    "    \"\"\"Generates three file names for the model, weights and history file and\n",
    "    the networks readme.\n",
    "\n",
    "    File name order of returned tuple:\n",
    "        * readme\n",
    "        * model\n",
    "        * weights\n",
    "        * history\n",
    "\n",
    "    :param uuid: Universal unique identifier of a trained network\n",
    "    :param name: The networks name\n",
    "    :return: Tuple with files in the order mentioned above\n",
    "    \"\"\"\n",
    "    base = f\"{NETWORK_PATH}/{str(uuid)}-{name}\"\n",
    "\n",
    "    f_readme = f\"{base}-readme.txt\"\n",
    "    f_model = f\"{base}-model.h5\"\n",
    "    f_weights = f\"{base}-weights.h5\"\n",
    "    f_history = f\"{base}-history\"\n",
    "\n",
    "    return (f_readme, f_model, f_weights, f_history)\n",
    "\n",
    "\n",
    "def export_model(m: ModelHistory):\n",
    "    \"\"\"If a model is sufficiently trained, it can be exported. This allows to\n",
    "    simply save the models state and the training history. Whenever one want to\n",
    "    use the model the next time, the training can be skipped, since the trained\n",
    "    model can just be imported from files.\n",
    "\n",
    "    :param model_history: The trained model and history to be stored\n",
    "    \"\"\"\n",
    "    f_readme, f_model, f_weights, f_history = get_file_names(m.uuid,m.name)\n",
    "\n",
    "    # save readme\n",
    "    with open(f_readme, 'w') as f:\n",
    "        f.write(m.readme)\n",
    "    print(f\"Exported README: {f_readme}\")\n",
    "\n",
    "    # save models & weights\n",
    "    m.model.save(f_model)\n",
    "    print(f\"Exported model: {f_model}\")\n",
    "    m.model.save_weights(f_weights)\n",
    "    print(f\"Exported weights: {f_weights}\")\n",
    "\n",
    "    # save history\n",
    "    with open(f_history, \"wb\") as f:\n",
    "        pickle.dump(m.history, f)\n",
    "    print(f\"Exported history: {f_history}\")\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return K.pow((1 - tv), gamma)\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'my_custom_func': focal_tversky_loss})\n",
    "\n",
    "def import_model(uuid, name):\n",
    "    \"\"\"Previously exported models can be imported with this funciton.\n",
    "    :param uuid: The networks uuid\n",
    "    :param name: The networks name\n",
    "    :return: Instance of ModelHistory\n",
    "    \"\"\"\n",
    "    f_readme, f_model, f_weights, f_history = get_file_names(uuid, name)\n",
    "\n",
    "    # Load readme\n",
    "    with open(f_readme, 'r') as f:\n",
    "        readme = \"\".join(f.readlines())\n",
    "    print(f\"Imported README: {f_readme}\")\n",
    "\n",
    "    # Load model & weights\n",
    "    model = tf.keras.models.load_model(f_model,compile = False)\n",
    "    print(f\"Imported model: {f_model}\")\n",
    "    model.load_weights(f_weights)\n",
    "    print(f\"Imported weights: {f_weights}\")\n",
    "\n",
    "    # Load history\n",
    "    with open(f_history, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    print(f\"Imported history: {f_history}\")\n",
    "\n",
    "    return ModelHistory(uuid, name, model, history, readme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8101,
     "status": "ok",
     "timestamp": 1647955897680,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "pDAHrTgfawNZ",
    "outputId": "5ccf1038-084b-4d7f-dbb1-b1bda28d6480"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Loading input data\n",
    "#\n",
    "# Input data is loaded into two dictionaries: \n",
    "#\n",
    "# images: contains the 4-band images. The values are loaded as ints.\n",
    "# labels: contains 3D arrays in which each pixel is assigned with \n",
    "#         a label \"1\" = other and \"2\" = field boundary\n",
    "#\n",
    "# ################################################################\n",
    "\n",
    "\n",
    "def key_generator(file_name):\n",
    "    \"\"\"Generates the key of a file based on the file name. The resulting key is\n",
    "    a tuple of the province as string & the file number index as int,\n",
    "    e.g. (\"gelderland\", 29)\n",
    "    \"\"\"\n",
    "    file_name = file_name.lower()\n",
    "    file_name = file_name.replace(\"classified_\", \"\")\n",
    "    file_name = file_name.replace(\"original_\", \"\")\n",
    "    file_name = file_name.replace(\".tif\", \"\")\n",
    "    # TODO: Some images are named incorrectly\n",
    "    #       (e.g. no '_' between the province name and the image index)\n",
    "    (province, index) = tuple(file_name.split(\"_\"))\n",
    "    index = int(index)\n",
    "    return (province, index)\n",
    "\n",
    "def gtiff_to_array_geo(file_path):\n",
    "    \"\"\"Takes a file path and returns a tif file as a 3-dimensional numpy array, width x height x bands.\"\"\"\n",
    "    data = gdal.Open(file_path)\n",
    "    bands = [data.GetRasterBand(i+1).ReadAsArray() for i in range(data.RasterCount)]\n",
    "    return np.stack(bands, axis=2), data.GetGeoTransform(), data.GetProjection()\n",
    "\n",
    "def gtiff_to_array(file_path):\n",
    "    \"\"\"Takes a file path and returns a tif file as a 3-dimensional numpy array, width x height x bands.\"\"\"\n",
    "    data = gdal.Open(file_path)\n",
    "    bands = [data.GetRasterBand(i+1).ReadAsArray() for i in range(data.RasterCount)]\n",
    "    return np.stack(bands, axis=2)\n",
    "\n",
    "\n",
    "def transform_classification_image(input):\n",
    "    \"\"\"Takes the classification image input (in RGB format as 3D array) and \n",
    "    creates a 2D array out of this. The innermost array expects either values of\n",
    "    [0, 0, 0] of [255, 255, 255] since this is the colouring we assigned to the\n",
    "    classified images.\n",
    "\n",
    "    :param input: 3D input image (classification)\n",
    "    :return: 2D array image with labels 1 for 'other' and 2 for 'field_boundaries'\n",
    "    \"\"\"\n",
    "\n",
    "    # Out of the 3D input array it takes the \"max\" element out of the array\n",
    "    # This will either be 0 or 255. This function is just called to transform \n",
    "    # the 3D array to a 2D array.\n",
    "    result = np.reshape(np.max(input, axis=2), (input.shape[0], input.shape[1], 1))\n",
    "\n",
    "    # Now the array consists of pixels with values \"0\" or \"255\". We transform\n",
    "    # each value, that is larger than 0 (i.e. 255) and assign the label \"2\" to\n",
    "    # it. Each other element (i.e. 0) will get assigned the label \"1\".\n",
    "    result = np.where(result > 0, 2, 1)\n",
    "    return result\n",
    "\n",
    "# Dictionaries which contain the input data\n",
    "x_dict = {}\n",
    "y_dict = {}\n",
    "geoTrans = {}\n",
    "geoProj = {}\n",
    "\n",
    "# Iterate through defined folders and load all image data into the dictionaries\n",
    "# image_data and label_data. Images can be accessed with (<province>, <index>)\n",
    "for folder in INCLUDE_FOLDERS:\n",
    "    original = INPUT_PATH + folder + IMAGE_PATH\n",
    "    classified = INPUT_PATH + folder + LABEL_PATH\n",
    "    for f in os.listdir(original): \n",
    "        key = key_generator(f)\n",
    "        x_dict[key], geoTrans[key], geoProj[key] = gtiff_to_array_geo(original + \"/\" + f)\n",
    "\n",
    "print(f\"Total number of image & label tiles: {len(x_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1647955897959,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "9487wKIZKZpU",
    "outputId": "ca1982a9-ed2d-40d7-e8e2-1b6f47962f76"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Normalizing images\n",
    "# \n",
    "# Normalizing all input images into values in the interval [0, 1].\n",
    "# All bands are normalized seperately, which means, the min & max\n",
    "# of each band is calculated based on each band of the image data.\n",
    "# ################################################################\n",
    "\n",
    "def normalize_array_1(arr):\n",
    "    \"\"\"Takes a 3D array as input, iterates over the bands and normalizes those.\n",
    "\n",
    "    :param arr: input array (original image data) \n",
    "    :return: normalized data with values between 0 and 1\n",
    "    \"\"\"\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        min = arr[:, :, i].min()\n",
    "        max = arr[:, :, i].max()\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - min) / (max - min)\n",
    "    return arr_norm\n",
    "\n",
    "def normalize_array_2(arr, minimum, maximum):\n",
    "\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - minimum[i]) / (maximum[i] - minimum[i])\n",
    "    return arr_norm\n",
    "\n",
    "def normalize_array_3(arr, mean, sd):\n",
    "    \n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - mean[i]) / sd[i]\n",
    "    return arr_norm\n",
    "\n",
    "def get_feature_mins_maxs(images):\n",
    "    \"\"\"get the means and standard deviations per band for all image data\n",
    "    :param image: list of image data\n",
    "    :return: minima and maxima per band\n",
    "    \"\"\"\n",
    "    features_mins = []\n",
    "    features_maxs = []\n",
    "    arr = np.array(images)\n",
    "    for i in range(arr.shape[-1]):\n",
    "        features_mins.append(np.min(arr[:, :, :, i]))\n",
    "        features_maxs.append(np.max(arr[:, :, :, i]))\n",
    "    return np.array(features_mins), np.array(features_maxs)\n",
    "\n",
    "features_mins, features_maxs = get_feature_mins_maxs(list(images.values()))\n",
    "for k, v in images.items():\n",
    "    images[k] = normalize_array_2(v, features_mins, features_maxs)\n",
    "    # images[k] = normalize_array_1(v)\n",
    "    print(f\"Performed normalization of {k[0]}_{k[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1647955898529,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "hzXD96NtZ3L1",
    "outputId": "faeca498-e5d6-470c-8595-1e6b4b36eb0e"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Network builder functions\n",
    "#\n",
    "# Dynamic builder function for the FCN-DK (supposted from layer 2 to 6)\n",
    "# and unet (layer 1 to 5).\n",
    "# ################################################################\n",
    "\n",
    "#import model_segnet_Nbands\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, Convolution2D, LeakyReLU, Reshape, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "# TODO: Consider which optimizer is the best\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "from keras_unet.models import satellite_unet\n",
    "\n",
    "def build_unet(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    "    layers: int = 2,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Create  a model of the popular U-Net network.\n",
    "\n",
    "    :param x: Number of rows (x-shape)\n",
    "    :param y: Number of columns (y-shape)\n",
    "    :param bands: Number of bands (z-shape)\n",
    "    :param lables: Number of labels to predict with the network\n",
    "    :param layers: Number of layers of the network\n",
    "    :return: Model of the corresponding U-Net network\n",
    "    \"\"\"\n",
    "    model = satellite_unet(\n",
    "        input_shape=(x, y, bands),\n",
    "        num_classes=labels,\n",
    "        output_activation=\"softmax\",\n",
    "        num_layers=layers,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_unet2(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 2 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=2)\n",
    "    \n",
    "def build_unet3(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 3 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=3)\n",
    "\n",
    "def build_unet5(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 5 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=5)\n",
    "    \n",
    "\n",
    "\n",
    "def build_fcndk(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    prediction: int,\n",
    "    labels: int,\n",
    "    layers=4,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Build a new network model based on the configuration of the networks \n",
    "    FCNDK2, ..., FCNDK6. Specify the layers to use in the parameters.\n",
    "\n",
    "    :param x: Number of rows\n",
    "    :param y: Number of columns\n",
    "    :param bands: Number of bands in the input images\n",
    "    :param labels: Number of different labels to choose as the classification\n",
    "    :param layers: The number of FCNDK layers; Should be between 2 and 6 [default: 4]\n",
    "    :return: Model of the corresponding FCNDK network\n",
    "    \"\"\"\n",
    "    \"\"\"Model builder function for FCN-DK6.\"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(ZeroPadding2D((2, 2), input_shape=(x, y, bands)))\n",
    "    model.add(Convolution2D(\n",
    "              filters=16,\n",
    "              kernel_size=(5, 5),\n",
    "              dilation_rate=(1, 1)))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 2:\n",
    "        # FCNDK2\n",
    "        model.add(ZeroPadding2D((4, 4)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(2, 2)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 3:\n",
    "        # FCNDK3\n",
    "        model.add(ZeroPadding2D((6, 6)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(3, 3)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 4:\n",
    "        # FCNDK4\n",
    "        model.add(ZeroPadding2D((8, 8)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(4, 4)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 5:\n",
    "        # FCNDK5\n",
    "        model.add(ZeroPadding2D((10, 10)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(5, 5)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 6:\n",
    "        # FCNDK6\n",
    "        model.add(ZeroPadding2D((12, 12)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(6, 6)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Convolution2D(\n",
    "              filters=labels,\n",
    "              kernel_size=(1, 1)\n",
    "    ))\n",
    "\n",
    "    model.add(keras.layers.Activation(\n",
    "              activation=\"softmax\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def build_fcndk3(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 3 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=3)\n",
    "    \n",
    "def build_fcndk4(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 4 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=4)\n",
    "\n",
    "def build_fcndk5(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 5 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=5)\n",
    "\n",
    "def build_fcndk6(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 6 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=6)\n",
    "\n",
    "\n",
    "def build_network(name: str) -> typing.Callable:\n",
    "    \"\"\"Builds a new network, based on the networks name\n",
    "    :param name: The networks name\n",
    "    :return: The builder function of the corresponding network.\n",
    "    \"\"\"\n",
    "    if name.lower() == \"fcndk3\":\n",
    "        return build_fcndk3\n",
    "    elif name.lower() == \"fcndk4\":\n",
    "        return build_fcndk4\n",
    "    elif name.lower() == \"fcndk5\":\n",
    "        return build_fcndk5\n",
    "    elif name.lower() == \"fcndk6\":\n",
    "        return build_fcndk6\n",
    "    elif name.lower() == \"unet2\":\n",
    "        return build_unet2\n",
    "    elif name.lower() == \"unet3\":\n",
    "        return build_unet3\n",
    "    elif name.lower() == \"unet5\":\n",
    "        return build_unet5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7291,
     "status": "ok",
     "timestamp": 1647955905818,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "Qba8oSlkZ3Lu",
    "outputId": "027aeb14-e1bb-44dc-af2d-9afc1648a4d2"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Creating network\n",
    "#\n",
    "# In this code block, the network configuration is loaded properly\n",
    "# and the corresponding builder function is called.\n",
    "# ################################################################\n",
    "\n",
    "NUMBER_BANDS = 4\n",
    "NUMBER_CLASSES = 2\n",
    "NUMBER_EPOCHS = 10\n",
    "NUMBER_BATCHES = 64\n",
    "VALIDATION_SPLIT = 0.02\n",
    "\n",
    "model_builder = build_network(NETWORK_NAME)\n",
    "\n",
    "# Optimizer (actually  not required anymore, but code legacy requires it.)\n",
    "if NETWORK_OPTIMIZER == \"Adam\":\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(\n",
    "        learning_rate=ADAM_LEARNING_RATE,\n",
    "        beta_1=ADAM_BETA_1, \n",
    "        beta_2=ADAM_BETA_2, \n",
    "        epsilon=ADAM_EPSILON\n",
    "    )\n",
    "elif NETWORK_OPTIMIZER == \"SGD\":\n",
    "    OPTIMIZER = tf.keras.optimizers.SGD(\n",
    "        learning_rate=SGD_LEARNING_RATE, \n",
    "        momentum=SGD_MOMENTUM\n",
    "    )\n",
    "\n",
    "# Load existing network from files\n",
    "m = import_model(NETWORK_UUID, NETWORK_NAME)\n",
    "readme = m.readme\n",
    "model = m.model\n",
    "history = m.history\n",
    "print(f\"Load existing network: {NETWORK_UUID} {NETWORK_NAME}\")\n",
    "\n",
    "# Print configuration README before (possible) training\n",
    "print(readme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647955905819,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "yaknOjT38cZS"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Predictions & export\n",
    "#\n",
    "# Here, the network is fed with the given input files. Resulting\n",
    "# predictions are exported as TIF files.\n",
    "# ################################################################\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "\n",
    "def evaluate_predictions(\n",
    "    input: np.ndarray,\n",
    "    nc: int,\n",
    "    f_weights: str,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    model_builder: typing.Callable,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Takes an input image, patches it into smaller patches and feeds the FCN\n",
    "    with each of the patches. The output samples are patches of the predicted\n",
    "    classification. These patches are combined into one large image, that can\n",
    "    be compared with the classified image of the corresponding input data.\n",
    "\n",
    "    :param input: test image to evaluate\n",
    "    :param nc: Number of classes/labels\n",
    "    :param f_weights: File path to the corresponding weights file\n",
    "    :param optimizer: Optimizer for the network\n",
    "    :param model_build: method to create the model\n",
    "    :return: 2D ndarray of the predicted labels\n",
    "    \"\"\"\n",
    "    x, y, bands = input.shape\n",
    "\n",
    "    # Build model and load model weights\n",
    "    model = model_builder(x, y, bands, nc)\n",
    "    # model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
    "    model.compile(optimizer=OPTIMIZER, loss=focal_tversky_loss, metrics='accuracy')\n",
    "    model.load_weights(f_weights)\n",
    "\n",
    "    # Predict field boundaries in network\n",
    "    # Increase dimension to perform batch prediction\n",
    "    input = np.expand_dims(input, 0)\n",
    "    prediction = model.predict(input)[0]\n",
    "    # Map highest score onto label\n",
    "    # prediction = np.argmax(prediction, axis=2) + 1\n",
    "    return prediction[:,:,1]\n",
    "\n",
    "def export_array(labels: np.ndarray, filename: str):\n",
    "    \"\"\"Maps labels onto the colors black & white and exports the resulting image\n",
    "    as a file with the given file.\n",
    "\n",
    "    :param labels: 2D array of labels per pixel\n",
    "    :param filename: File name of the new file\n",
    "    \"\"\"\n",
    "    x, y = labels.shape\n",
    "\n",
    "    img = np.zeros((x, y, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(img.shape[2]):\n",
    "        img[:, :, i] = np.where(labels[:, :] == 2, 255, 0)\n",
    "\n",
    "    Image.fromarray(img).save(filename)\n",
    "    #Image.fromarray(img).save()\n",
    "    #pyplot.imsave(filename, Image.fromarray(img))\n",
    "\n",
    "def export_geotiff(labels: np.ndarray, geoTrans, geoProj, filename: str):\n",
    "    \"\"\"Maps labels onto the colors black & white and exports the resulting image\n",
    "    as a file with the given file.\n",
    "\n",
    "    :param labels: 2D array of labels per pixel\n",
    "    :param filename: File name of the new file\n",
    "    \"\"\"\n",
    "    x, y = labels.shape\n",
    "    # labels[:, :] = np.where(labels[:, :] == 2, 65535, 0)\n",
    "    labels[:, :] *= 65535\n",
    "    # import matplotlib.pylab as plt\n",
    "    # plt.hist(labels.reshape(x*y)); plt.show()\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    outData = driver.Create(filename, x, y, 3, gdal.GDT_UInt16)\n",
    "\n",
    "    # Write metadata\n",
    "    outData.SetGeoTransform(geoTrans)\n",
    "    outData.SetProjection(geoProj)\n",
    "\n",
    "    # Write raster data sets\n",
    "    for i in range(3):\n",
    "      outData.GetRasterBand(i+1).WriteArray(labels)\n",
    "    outData.FlushCache()\n",
    "    outData = None     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35790,
     "status": "ok",
     "timestamp": 1647955941605,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "iqWLGyUIJjm4",
    "outputId": "b8b6119d-5d95-4d8e-e66c-d46f2ddfcb88"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Predict images and store as TIF\n",
    "#\n",
    "# This code block will iterate through the included folders and\n",
    "# performs predictions on the satellite image tiles. The resulting\n",
    "# images are mapped onto black & white and then exported as TIF\n",
    "# files\n",
    "# ################################################################\n",
    "\n",
    "import pathlib\n",
    "\n",
    "\n",
    "keys_per_province = dict()\n",
    "\n",
    "for f in INCLUDE_FOLDERS:\n",
    "    keys_per_province[f] = [k for k in x_dict.keys() if k[0].lower() == f.lower()]\n",
    "\n",
    "for f, keys in keys_per_province.items():\n",
    "    for k in keys:\n",
    "        x = x_dict[k]\n",
    "\n",
    "        (_, _, f_weights, _) = get_file_names(NETWORK_UUID, NETWORK_NAME)\n",
    "\n",
    "        try:\n",
    "            img = evaluate_predictions(\n",
    "                x,\n",
    "                NUMBER_CLASSES,\n",
    "                f_weights,\n",
    "                OPTIMIZER,\n",
    "                model_builder,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to predict image of size {x.shape[0]}x{x.shape[1]}\")\n",
    "            continue\n",
    "\n",
    "        # Build directory name\n",
    "        fname = PREDICTION_PATH\n",
    "        fname += f\"{f}/\"\n",
    "        fname += f\"Prediction_{NETWORK_NAME}/\"\n",
    "\n",
    "        # Create directory\n",
    "        pathlib.Path(fname).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # build filename\n",
    "        fname += f\"prediction_{k[0]}_{k[1]}\"\n",
    "        fname += \".tif\"\n",
    "\n",
    "        # export_array(img, fname)\n",
    "        export_geotiff(img, geoTrans[k],geoProj[k],fname)\n",
    "        print(f\"Exported prediction {fname}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "network-prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
