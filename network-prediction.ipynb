{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZeSZWtxITOh"
   },
   "source": [
    "# Automatic delineation of field boundaries on satellite images\n",
    "\n",
    "```\n",
    "TODO: Add intro\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8956,
     "status": "ok",
     "timestamp": 1647955869433,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "GYebLccZbPcz",
    "outputId": "5ce6751d-8aa0-4abf-ca18-2172f33e3d3c"
   },
   "outputs": [],
   "source": [
    "# Mount google drive folder\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16406,
     "status": "ok",
     "timestamp": 1647955885837,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "xFDIcczJKJEZ",
    "outputId": "2916e053-104b-4955-ae1a-9adef403d207"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 14:17:16.474236: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/lib/jvm/java-11-openjdk-amd64/lib/server:/opt/hadoop/lib/native:/usr/local/lib/R/lib:/usr/local/grass82/lib\n",
      "2022-08-08 14:17:16.474281: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/karolzak/keras-unet\n",
      "  Cloning https://github.com/karolzak/keras-unet to /tmp/pip-req-build-k9ndi3o_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/karolzak/keras-unet /tmp/pip-req-build-k9ndi3o_\n",
      "  Resolved https://github.com/karolzak/keras-unet to commit 9b7aff5247fff75dc4e2a11ba9c45929b9166d1f\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/__main__.py\", line 31, in <module>\n",
      "    sys.exit(_main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.1', new='22.2.2'),)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import typing\n",
    "from osgeo import gdal\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "# Install keras-unet library for python\n",
    "#%pip uninstall keras-unet\n",
    "%pip install git+https://github.com/karolzak/keras-unet\n",
    "\n",
    "# # define dataset directory\n",
    "# from google.colab import drive\n",
    "\n",
    "BASE_PATH = \"/home/jovyan/private/Agricultural_Field_Boundary\"\n",
    "DATA_PATH = BASE_PATH + \"/original/\"\n",
    "NETWORK_PATH = BASE_PATH + \"/Networks\"\n",
    "IMAGE_PATH = \"/Original\"\n",
    "LABEL_PATH = \"/Classified\"\n",
    "PREDICTION_PATH = \"/Prediction\"\n",
    "\n",
    "# INCLUDE_FOLDERS = [\"Flevoland\", \"Friesland\", \"Gelderland\", \"Limburg\", \"Overijssel\", \"Zeeland\", \"Zuid-Holland\",\"Vietnam\",\"Cambodia\"]\n",
    "INCLUDE_FOLDERS = [\"Vietnam\"]\n",
    "LEGEND = {\n",
    "    1: 'Other',\n",
    "    2: 'Field Boundary'\n",
    "}\n",
    "\n",
    "\n",
    "# To assess the accuracy you have to define the networks UUID and name here\n",
    "NETWORK_UUID = \"6c0f7e24-a85a-11ec-938c-02420a0001f1\"\n",
    "\n",
    "# Allowed Values:\n",
    "#   * FCNDK3\n",
    "#   * FCNDK4\n",
    "#   * FCNDK5\n",
    "#   * FCNDK6\n",
    "#   * UNet2\n",
    "#   * UNet3\n",
    "NETWORK_NAME = \"UNet5\"\n",
    "\n",
    "\n",
    "# To compile the model, also the optimizer has to be defined\n",
    "NETWORK_OPTIMIZER = \"Adam\"\n",
    "\n",
    "# Ensure you use the same optimizer parameters as in the training run\n",
    "SGD_LEARNING_RATE = 0.01\n",
    "SGD_MOMENTUM = 0.9\n",
    "ADAM_LEARNING_RATE = 0.01\n",
    "ADAM_BETA_1 = 0.9\n",
    "ADAM_BETA_2 = 0.999\n",
    "ADAM_EPSILON= 1e-07\n",
    "\n",
    "\n",
    "# Remark: All information in here could have been loaded from the training\n",
    "#         configuration file as well. However, we missed the chance to export\n",
    "#         the configuration as a machine readable type, e.g. JSON.\n",
    "#         Thus, we did not pass the config from the readme manually but set the\n",
    "#         parameters manually in here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3367,
     "status": "ok",
     "timestamp": 1647955889199,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "sB6fZzP744dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 14:17:44.958850: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/lib/jvm/java-11-openjdk-amd64/lib/server:/opt/hadoop/lib/native:/usr/local/lib/R/lib:/usr/local/grass82/lib\n",
      "2022-08-08 14:17:44.958886: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-08 14:17:44.958911: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (e9d769088e9b): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Prerequisites for the network\n",
    "#\n",
    "# Includes a few helper functions which will be used to create and\n",
    "# evaluate the network, the training and the accuracy.\n",
    "# ################################################################\n",
    "\n",
    "import imp, h5py\n",
    "import dill, pickle\n",
    "import uuid\n",
    "imp.reload(h5py)\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "sess = K.get_session()\n",
    "\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "\n",
    "# Tensorflow configuration\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.2\n",
    "set_session(tf.compat.v1.Session(config=config))\n",
    "\n",
    "\n",
    "\n",
    "# Helper functions for the networks\n",
    "\n",
    "# ################################################################\n",
    "# Helper functions - import/export of network\n",
    "#\n",
    "# These two functions help to export the network and import it.\n",
    "# That allows to skip the training at a later stage.\n",
    "# ################################################################\n",
    "\n",
    "class ModelHistory:\n",
    "    \"\"\"Just a small container class to hold relevant information of a trained\n",
    "    model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, uuid, name, model, history, readme):\n",
    "        \"\"\"Create a new instance of this class\n",
    "        :param uuid: A unique identifier of the network\n",
    "        :param name: The networks name\n",
    "        :param model: The pretrained model\n",
    "        :param history: The training history of the model\n",
    "        :param readme: A small readme with a summary of training parameters\n",
    "        \"\"\"\n",
    "        self.uuid = uuid\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.history = history\n",
    "        self.readme = readme\n",
    "\n",
    "\n",
    "def get_file_names(uuid, name):\n",
    "    \"\"\"Generates three file names for the model, weights and history file and\n",
    "    the networks readme.\n",
    "\n",
    "    File name order of returned tuple:\n",
    "        * readme\n",
    "        * model\n",
    "        * weights\n",
    "        * history\n",
    "\n",
    "    :param uuid: Universal unique identifier of a trained network\n",
    "    :param name: The networks name\n",
    "    :return: Tuple with files in the order mentioned above\n",
    "    \"\"\"\n",
    "    base = f\"{NETWORK_PATH}/{str(uuid)}-{name}\"\n",
    "\n",
    "    f_readme = f\"{base}-readme.txt\"\n",
    "    f_model = f\"{base}-model.h5\"\n",
    "    f_weights = f\"{base}-weights.h5\"\n",
    "    f_history = f\"{base}-history\"\n",
    "\n",
    "    return (f_readme, f_model, f_weights, f_history)\n",
    "\n",
    "\n",
    "def export_model(m: ModelHistory):\n",
    "    \"\"\"If a model is sufficiently trained, it can be exported. This allows to\n",
    "    simply save the models state and the training history. Whenever one want to\n",
    "    use the model the next time, the training can be skipped, since the trained\n",
    "    model can just be imported from files.\n",
    "\n",
    "    :param model_history: The trained model and history to be stored\n",
    "    \"\"\"\n",
    "    f_readme, f_model, f_weights, f_history = get_file_names(m.uuid,m.name)\n",
    "\n",
    "    # save readme\n",
    "    with open(f_readme, 'w') as f:\n",
    "        f.write(m.readme)\n",
    "    print(f\"Exported README: {f_readme}\")\n",
    "\n",
    "    # save models & weights\n",
    "    m.model.save(f_model)\n",
    "    print(f\"Exported model: {f_model}\")\n",
    "    m.model.save_weights(f_weights)\n",
    "    print(f\"Exported weights: {f_weights}\")\n",
    "\n",
    "    # save history\n",
    "    with open(f_history, \"wb\") as f:\n",
    "        pickle.dump(m.history, f)\n",
    "    print(f\"Exported history: {f_history}\")\n",
    "\n",
    "def tversky(y_true, y_pred, smooth=1, alpha=0.7):\n",
    "    y_true_pos = K.flatten(y_true)\n",
    "    y_pred_pos = K.flatten(y_pred)\n",
    "    true_pos = K.sum(y_true_pos * y_pred_pos)\n",
    "    false_neg = K.sum(y_true_pos * (1 - y_pred_pos))\n",
    "    false_pos = K.sum((1 - y_true_pos) * y_pred_pos)\n",
    "    return (true_pos + smooth) / (true_pos + alpha * false_neg + (1 - alpha) * false_pos + smooth)\n",
    "\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    return 1 - tversky(y_true, y_pred)\n",
    "\n",
    "\n",
    "def focal_tversky_loss(y_true, y_pred, gamma=0.75):\n",
    "    tv = tversky(y_true, y_pred)\n",
    "    return K.pow((1 - tv), gamma)\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "\n",
    "get_custom_objects().update({'my_custom_func': focal_tversky_loss})\n",
    "\n",
    "def import_model(uuid, name):\n",
    "    \"\"\"Previously exported models can be imported with this funciton.\n",
    "    :param uuid: The networks uuid\n",
    "    :param name: The networks name\n",
    "    :return: Instance of ModelHistory\n",
    "    \"\"\"\n",
    "    f_readme, f_model, f_weights, f_history = get_file_names(uuid, name)\n",
    "\n",
    "    # Load readme\n",
    "    with open(f_readme, 'r') as f:\n",
    "        readme = \"\".join(f.readlines())\n",
    "    print(f\"Imported README: {f_readme}\")\n",
    "\n",
    "    # Load model & weights\n",
    "    model = tf.keras.models.load_model(f_model,compile = False)\n",
    "    print(f\"Imported model: {f_model}\")\n",
    "    model.load_weights(f_weights)\n",
    "    print(f\"Imported weights: {f_weights}\")\n",
    "\n",
    "    # Load history\n",
    "    with open(f_history, 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "    print(f\"Imported history: {f_history}\")\n",
    "\n",
    "    return ModelHistory(uuid, name, model, history, readme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8101,
     "status": "ok",
     "timestamp": 1647955897680,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "pDAHrTgfawNZ",
    "outputId": "5ccf1038-084b-4d7f-dbb1-b1bda28d6480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of image & label tiles: 6\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Loading input data\n",
    "#\n",
    "# Input data is loaded into two dictionaries: \n",
    "#\n",
    "# images: contains the 4-band images. The values are loaded as ints.\n",
    "# labels: contains 3D arrays in which each pixel is assigned with \n",
    "#         a label \"1\" = other and \"2\" = field boundary\n",
    "#\n",
    "# ################################################################\n",
    "\n",
    "\n",
    "def key_generator(file_name):\n",
    "    \"\"\"Generates the key of a file based on the file name. The resulting key is\n",
    "    a tuple of the province as string & the file number index as int,\n",
    "    e.g. (\"gelderland\", 29)\n",
    "    \"\"\"\n",
    "    file_name = file_name.lower()\n",
    "    file_name = file_name.replace(\"classified_\", \"\")\n",
    "    file_name = file_name.replace(\"original_\", \"\")\n",
    "    file_name = file_name.replace(\".tif\", \"\")\n",
    "    # TODO: Some images are named incorrectly\n",
    "    #       (e.g. no '_' between the province name and the image index)\n",
    "    (province, index) = tuple(file_name.split(\"_\"))\n",
    "    index = int(index)\n",
    "    return (province, index)\n",
    "\n",
    "def gtiff_to_array_geo(file_path):\n",
    "    \"\"\"Takes a file path and returns a tif file as a 3-dimensional numpy array, width x height x bands.\"\"\"\n",
    "    data = gdal.Open(file_path)\n",
    "    bands = [data.GetRasterBand(i+1).ReadAsArray() for i in range(data.RasterCount)]\n",
    "    return np.stack(bands, axis=2), data.GetGeoTransform(), data.GetProjection()\n",
    "\n",
    "def gtiff_to_array(file_path):\n",
    "    \"\"\"Takes a file path and returns a tif file as a 3-dimensional numpy array, width x height x bands.\"\"\"\n",
    "    data = gdal.Open(file_path)\n",
    "    bands = [data.GetRasterBand(i+1).ReadAsArray() for i in range(data.RasterCount)]\n",
    "    return np.stack(bands, axis=2)\n",
    "\n",
    "\n",
    "def transform_classification_image(input):\n",
    "    \"\"\"Takes the classification image input (in RGB format as 3D array) and \n",
    "    creates a 2D array out of this. The innermost array expects either values of\n",
    "    [0, 0, 0] of [255, 255, 255] since this is the colouring we assigned to the\n",
    "    classified images.\n",
    "\n",
    "    :param input: 3D input image (classification)\n",
    "    :return: 2D array image with labels 1 for 'other' and 2 for 'field_boundaries'\n",
    "    \"\"\"\n",
    "\n",
    "    # Out of the 3D input array it takes the \"max\" element out of the array\n",
    "    # This will either be 0 or 255. This function is just called to transform \n",
    "    # the 3D array to a 2D array.\n",
    "    result = np.reshape(np.max(input, axis=2), (input.shape[0], input.shape[1], 1))\n",
    "\n",
    "    # Now the array consists of pixels with values \"0\" or \"255\". We transform\n",
    "    # each value, that is larger than 0 (i.e. 255) and assign the label \"2\" to\n",
    "    # it. Each other element (i.e. 0) will get assigned the label \"1\".\n",
    "    result = np.where(result > 0, 2, 1)\n",
    "    return result\n",
    "\n",
    "# Dictionaries which contain the input data\n",
    "x_dict = {}\n",
    "y_dict = {}\n",
    "geoTrans = {}\n",
    "geoProj = {}\n",
    "\n",
    "# Iterate through defined folders and load all image data into the dictionaries\n",
    "# image_data and label_data. Images can be accessed with (<province>, <index>)\n",
    "for folder in INCLUDE_FOLDERS:\n",
    "    original = DATA_PATH + folder + IMAGE_PATH\n",
    "    classified = DATA_PATH + folder + LABEL_PATH\n",
    "    for f in os.listdir(original): \n",
    "        key = key_generator(f)\n",
    "        x_dict[key], geoTrans[key], geoProj[key] = gtiff_to_array_geo(original + \"/\" + f)\n",
    "\n",
    "    # for f in os.listdir(classified): \n",
    "    #     key = key_generator(f)\n",
    "    #     value, _, _ = gtiff_to_array(classified + \"/\" + f) \n",
    "    #     # Transform the classification image from RGB to labels \"1\" and \"2\"\n",
    "    #     y_dict[key] = transform_classification_image(value)\n",
    "\n",
    "print(f\"Total number of image & label tiles: {len(x_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1647955897959,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "9487wKIZKZpU",
    "outputId": "ca1982a9-ed2d-40d7-e8e2-1b6f47962f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performed normalization of vietnam_24\n",
      "Performed normalization of vietnam_23\n",
      "Performed normalization of vietnam_20\n",
      "Performed normalization of vietnam_27\n",
      "Performed normalization of vietnam_26\n",
      "Performed normalization of vietnam_21\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Normalizing images\n",
    "# \n",
    "# Normalizing all input images into values in the interval [0, 1].\n",
    "# All bands are normalized seperately, which means, the min & max\n",
    "# of each band is calculated based on each band of the image data.\n",
    "# ################################################################\n",
    "\n",
    "def normalize(val, min, max):\n",
    "    \"\"\"Normalizes the value of a single pixel. Takes into account the minimum,\n",
    "    and maximum value.\n",
    "\n",
    "    v_normalized = (v - min) / (max - min)\n",
    "\n",
    "    :param val: integer value\n",
    "    :param min: integer minimum\n",
    "    :param max: integer maximum\n",
    "    :return: single floating point number in [0, 1]\n",
    "    \"\"\"\n",
    "    # TODO: check if necessary, otherwise delete\n",
    "    return (val - min) / (max - min)\n",
    "\n",
    "\n",
    "def normalize_array_1(arr):\n",
    "    \"\"\"Takes a 3D array as input, iterates over the bands and normalizes those.\n",
    "\n",
    "    :param arr: input array (original image data) \n",
    "    :return: normalized data with values between 0 and 1\n",
    "    \"\"\"\n",
    "    # result = np.reshape(np.min(arr, axis=2), (arr.shape[0], arr.shape[1], 1))\n",
    "    # result = np.where(result < 0, 0, result)\n",
    "\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        min = arr[:, :, i].min()\n",
    "        max = arr[:, :, i].max()\n",
    "        arr_norm = (arr - min) / (max - min)\n",
    "    return arr_norm\n",
    "\n",
    "\n",
    "def normalize_array_2(arr, minimum, maximum):\n",
    "    \"\"\"Takes a 3D array as input, iterates over the bands and normalizes those.\n",
    "\n",
    "    :param arr: input array (original image data) \n",
    "    :return: normalized data with values between 0 and 1\n",
    "    \"\"\"\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        arr_norm[:,:,i] = (arr[:,:,i] - minimum[i]) / (maximum[i] - minimum[i])\n",
    "    return arr_norm\n",
    "\n",
    "def normalize_array_with_mins_maxs(arr,mins,maxs):\n",
    "    \"\"\"Takes a 3D array as input, iterates over the bands and normalizes those.\n",
    "\n",
    "    :param arr: input array (original image data) \n",
    "    :return: normalized data with values between 0 and 1\n",
    "    \"\"\"\n",
    "    # result = np.reshape(np.min(arr, axis=2), (arr.shape[0], arr.shape[1], 1))\n",
    "    # result = np.where(result < 0, 0, result)\n",
    "\n",
    "    arr_norm = np.zeros(arr.shape, dtype=np.float32)\n",
    "\n",
    "    for i in range(arr.shape[2]):\n",
    "        min = arr[:, :, i].min()\n",
    "        max = arr[:, :, i].max()\n",
    "        arr_norm[:, :, i] = (arr[:, :, i] - min) * ((maxs[i] - mins[i])/(max - min)) + mins[i]\n",
    "    return arr_norm\n",
    "\n",
    "# minimum and maximum for 5m buffer dataset (WGS1984)\n",
    "# minimum = [302, 587, 392, 920]\n",
    "# maximum = [2500, 3264, 4000, 5900]\n",
    "# minimum and maximum for 7m buffer dataset (Mercator_Auxiliary_Sphere)\n",
    "# minimum = [314, 587, 390, 913]\n",
    "# maximum = [2500, 3264, 4000, 5857]\n",
    "# minimum and maximum for 7m buffer single day image (Mercator_Auxiliary_Sphere)\n",
    "minimum = [160, 332, 323, 367]\n",
    "maximum = [3163, 4190, 5234, 4918]\n",
    "for k, v in x_dict.items():\n",
    "    x_dict[k] = normalize_array_2(v, minimum, maximum)\n",
    "    print(f\"Performed normalization of {k[0]}_{k[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1647955898529,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "hzXD96NtZ3L1",
    "outputId": "faeca498-e5d6-470c-8595-1e6b4b36eb0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Network builder functions\n",
    "#\n",
    "# Dynamic builder function for the FCN-DK (supposted from layer 2 to 6)\n",
    "# and unet (layer 1 to 5).\n",
    "# ################################################################\n",
    "\n",
    "#import model_segnet_Nbands\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, Convolution2D, LeakyReLU, Reshape, ZeroPadding2D\n",
    "from keras.models import Sequential\n",
    "# TODO: Consider which optimizer is the best\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "\n",
    "from keras_unet.models import satellite_unet\n",
    "\n",
    "def build_unet(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    "    layers: int = 2,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Create  a model of the popular U-Net network.\n",
    "\n",
    "    :param x: Number of rows (x-shape)\n",
    "    :param y: Number of columns (y-shape)\n",
    "    :param bands: Number of bands (z-shape)\n",
    "    :param lables: Number of labels to predict with the network\n",
    "    :param layers: Number of layers of the network\n",
    "    :return: Model of the corresponding U-Net network\n",
    "    \"\"\"\n",
    "    model = satellite_unet(\n",
    "        input_shape=(x, y, bands),\n",
    "        num_classes=labels,\n",
    "        output_activation=\"softmax\",\n",
    "        num_layers=layers,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def build_unet2(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 2 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=2)\n",
    "    \n",
    "def build_unet3(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 3 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=3)\n",
    "\n",
    "def build_unet5(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an UNet with 5 layers\n",
    "    \"\"\"\n",
    "    return build_unet(x, y, bands, labels, layers=5)\n",
    "    \n",
    "\n",
    "\n",
    "def build_fcndk(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    prediction: int,\n",
    "    labels: int,\n",
    "    layers=4,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Build a new network model based on the configuration of the networks \n",
    "    FCNDK2, ..., FCNDK6. Specify the layers to use in the parameters.\n",
    "\n",
    "    :param x: Number of rows\n",
    "    :param y: Number of columns\n",
    "    :param bands: Number of bands in the input images\n",
    "    :param labels: Number of different labels to choose as the classification\n",
    "    :param layers: The number of FCNDK layers; Should be between 2 and 6 [default: 4]\n",
    "    :return: Model of the corresponding FCNDK network\n",
    "    \"\"\"\n",
    "    \"\"\"Model builder function for FCN-DK6.\"\"\"\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(ZeroPadding2D((2, 2), input_shape=(x, y, bands)))\n",
    "    model.add(Convolution2D(\n",
    "              filters=16,\n",
    "              kernel_size=(5, 5),\n",
    "              dilation_rate=(1, 1)))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 2:\n",
    "        # FCNDK2\n",
    "        model.add(ZeroPadding2D((4, 4)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(2, 2)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 3:\n",
    "        # FCNDK3\n",
    "        model.add(ZeroPadding2D((6, 6)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(3, 3)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 4:\n",
    "        # FCNDK4\n",
    "        model.add(ZeroPadding2D((8, 8)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(4, 4)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 5:\n",
    "        # FCNDK5\n",
    "        model.add(ZeroPadding2D((10, 10)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(5, 5)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    if layers >= 6:\n",
    "        # FCNDK6\n",
    "        model.add(ZeroPadding2D((12, 12)))\n",
    "        model.add(Convolution2D(\n",
    "                filters=32,\n",
    "                kernel_size=(5, 5),\n",
    "                dilation_rate=(6, 6)\n",
    "        ))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(LeakyReLU(0.1))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Convolution2D(\n",
    "              filters=labels,\n",
    "              kernel_size=(1, 1)\n",
    "    ))\n",
    "\n",
    "    model.add(keras.layers.Activation(\n",
    "              activation=\"softmax\"\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def build_fcndk3(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 3 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=3)\n",
    "    \n",
    "def build_fcndk4(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 4 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=4)\n",
    "\n",
    "def build_fcndk5(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 5 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=5)\n",
    "\n",
    "def build_fcndk6(\n",
    "    x: int,\n",
    "    y: int,\n",
    "    bands: int,\n",
    "    labels: int,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Wrapper function to build an FCNDK with 6 layers\n",
    "    \"\"\"\n",
    "    return build_fcndk(x, y, bands, labels, layers=6)\n",
    "\n",
    "\n",
    "def build_network(name: str) -> typing.Callable:\n",
    "    \"\"\"Builds a new network, based on the networks name\n",
    "    :param name: The networks name\n",
    "    :return: The builder function of the corresponding network.\n",
    "    \"\"\"\n",
    "    if name.lower() == \"fcndk3\":\n",
    "        return build_fcndk3\n",
    "    elif name.lower() == \"fcndk4\":\n",
    "        return build_fcndk4\n",
    "    elif name.lower() == \"fcndk5\":\n",
    "        return build_fcndk5\n",
    "    elif name.lower() == \"fcndk6\":\n",
    "        return build_fcndk6\n",
    "    elif name.lower() == \"unet2\":\n",
    "        return build_unet2\n",
    "    elif name.lower() == \"unet3\":\n",
    "        return build_unet3\n",
    "    elif name.lower() == \"unet5\":\n",
    "        return build_unet5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7291,
     "status": "ok",
     "timestamp": 1647955905818,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "Qba8oSlkZ3Lu",
    "outputId": "027aeb14-e1bb-44dc-af2d-9afc1648a4d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported README: /home/jovyan/private/Agricultural_Field_Boundary/Networks/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-readme.txt\n",
      "Imported model: /home/jovyan/private/Agricultural_Field_Boundary/Networks/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-model.h5\n",
      "Imported weights: /home/jovyan/private/Agricultural_Field_Boundary/Networks/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-weights.h5\n",
      "Imported history: /home/jovyan/private/Agricultural_Field_Boundary/Networks/6c0f7e24-a85a-11ec-938c-02420a0001f1-UNet5-history\n",
      "Load existing network: 6c0f7e24-a85a-11ec-938c-02420a0001f1 UNet5\n",
      "\n",
      "Training configuration\n",
      "================================\n",
      "Network\n",
      "    UUID:               6c0f7e24-a85a-11ec-938c-02420a0001f1\n",
      "    Name:               UNet5\n",
      "    Optimizer:          Adam\n",
      "\n",
      "Parameters\n",
      "    Bands:              4\n",
      "    Classes:            2\n",
      "    Epochs:             600\n",
      "    Batch Size:         8\n",
      "\n",
      "Optimizer (Adam)\n",
      "    Learning Rate:      0.0015\n",
      "    Beta 1:             0.9\n",
      "    Beta 2:             0.999\n",
      "    Epsilon:            1e-06\n",
      "    \n",
      "Execution summary\n",
      "    Patches:            760\n",
      "    Validation Split:   0.05\n",
      "    Resolution (px):    256x256\n",
      "    Bands:              4\n",
      "    Classes:            1\n",
      "\n",
      "Training Set:\n",
      "    (flevoland, 21)\n",
      "    (overijssel, 14)\n",
      "    (zeeland, 76)\n",
      "    (overijssel, 32)\n",
      "    (friesland, 178)\n",
      "    (friesland, 123)\n",
      "    (limburg, 110)\n",
      "    (zeeland, 51)\n",
      "    (zeeland, 5)\n",
      "    (zeeland, 23)\n",
      "    (overijssel, 98)\n",
      "    (overijssel, 43)\n",
      "    (friesland, 180)\n",
      "    (friesland, 134)\n",
      "    (zeeland, 62)\n",
      "    (zeeland, 7)\n",
      "    (overijssel, 18)\n",
      "    (limburg, 96)\n",
      "    (overijssel, 45)\n",
      "    (flevoland, 64)\n",
      "    (friesland, 136)\n",
      "    (overijssel, 2)\n",
      "    (zeeland, 64)\n",
      "    (zeeland, 9)\n",
      "    (overijssel, 20)\n",
      "    (zeeland, 18)\n",
      "    (overijssel, 29)\n",
      "    (friesland, 175)\n",
      "    (flevoland, 66)\n",
      "    (zeeland, 48)\n",
      "    (gelderland, 29)\n",
      "    (friesland, 150)\n",
      "    (limburg, 82)\n",
      "    (overijssel, 31)\n",
      "    (flevoland, 50)\n",
      "    (friesland, 177)\n",
      "    (zeeland, 32)\n",
      "    (zeeland, 50)\n",
      "    (overijssel, 6)\n",
      "    (overijssel, 70)\n",
      "    (overijssel, 15)\n",
      "    (flevoland, 34)\n",
      "    (overijssel, 33)\n",
      "    (friesland, 161)\n",
      "    (flevoland, 52)\n",
      "    (friesland, 179)\n",
      "    (zeeland, 34)\n",
      "    (flevoland, 36)\n",
      "    (zeeland, 36)\n",
      "    (overijssel, 56)\n",
      "    (overijssel, 1)\n",
      "    (zeeland, 63)\n",
      "    (friesland, 138)\n",
      "    (flevoland, 20)\n",
      "    (overijssel, 19)\n",
      "    (flevoland, 93)\n",
      "    (zeeland, 20)\n",
      "    (zeeland, 47)\n",
      "    (overijssel, 58)\n",
      "    (friesland, 195)\n",
      "    (flevoland, 22)\n",
      "    (zeeland, 22)\n",
      "    (zeeland, 31)\n",
      "    (overijssel, 60)\n",
      "    (zuid-holland, 114)\n",
      "    (gelderland, 30)\n",
      "    (flevoland, 79)\n",
      "    (zeeland, 6)\n",
      "    (zeeland, 33)\n",
      "    (overijssel, 44)\n",
      "    (overijssel, 7)\n",
      "    (overijssel, 71)\n",
      "    (zeeland, 8)\n",
      "    (friesland, 162)\n",
      "    (flevoland, 108)\n",
      "    (zeeland, 35)\n",
      "    (overijssel, 46)\n",
      "    (flevoland, 65)\n",
      "    (friesland, 137)\n",
      "    (flevoland, 37)\n",
      "    (overijssel, 21)\n",
      "    (zeeland, 19)\n",
      "    (overijssel, 30)\n",
      "    (zeeland, 37)\n",
      "    (overijssel, 57)\n",
      "Test Set:\n",
      "    (friesland, 148)\n",
      "    (zeeland, 3)\n",
      "    (overijssel, 17)\n",
      "    (friesland, 151)\n",
      "    (flevoland, 94)\n",
      "    (overijssel, 84)\n",
      "    (zeeland, 21)\n",
      "    (friesland, 163)\n",
      "    (zeeland, 24)\n",
      "    (friesland, 166)\n",
      "    (flevoland, 51)\n",
      "    (overijssel, 35)\n",
      "    (limburg, 165)\n",
      "    (zuid-holland, 101)\n",
      "    (overijssel, 59)\n",
      "    (friesland, 135)\n",
      "    (overijssel, 4)\n",
      "    (overijssel, 74)\n",
      "    (overijssel, 16)\n",
      "    (friesland, 165)\n",
      "    (overijssel, 34)\n",
      "    (zuid-holland, 100)\n",
      "    (overijssel, 3)\n",
      "    (flevoland, 80)\n",
      "    (zeeland, 4)\n",
      "    (gelderland, 37)\n",
      "    (friesland, 149)\n",
      "    (zeeland, 10)\n",
      "    (friesland, 152)\n",
      "    (flevoland, 95)\n",
      "    (zeeland, 77)\n",
      "    (friesland, 164)\n",
      "    (flevoland, 107)\n",
      "    (limburg, 166)\n",
      "    (friesland, 176)\n",
      "    (zeeland, 49)\n",
      "    (overijssel, 5)\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Creating network\n",
    "#\n",
    "# In this code block, the network configuration is loaded properly\n",
    "# and the corresponding builder function is called.\n",
    "# ################################################################\n",
    "\n",
    "NUMBER_BANDS = 4\n",
    "NUMBER_CLASSES = 2\n",
    "NUMBER_EPOCHS = 10\n",
    "NUMBER_BATCHES = 64\n",
    "VALIDATION_SPLIT = 0.02\n",
    "\n",
    "model_builder = build_network(NETWORK_NAME)\n",
    "\n",
    "# Optimizer (actually  not required anymore, but code legacy requires it.)\n",
    "if NETWORK_OPTIMIZER == \"Adam\":\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(\n",
    "        learning_rate=ADAM_LEARNING_RATE,\n",
    "        beta_1=ADAM_BETA_1, \n",
    "        beta_2=ADAM_BETA_2, \n",
    "        epsilon=ADAM_EPSILON\n",
    "    )\n",
    "elif NETWORK_OPTIMIZER == \"SGD\":\n",
    "    OPTIMIZER = tf.keras.optimizers.SGD(\n",
    "        learning_rate=SGD_LEARNING_RATE, \n",
    "        momentum=SGD_MOMENTUM\n",
    "    )\n",
    "\n",
    "# Load existing network from files\n",
    "m = import_model(NETWORK_UUID, NETWORK_NAME)\n",
    "readme = m.readme\n",
    "model = m.model\n",
    "history = m.history\n",
    "print(f\"Load existing network: {NETWORK_UUID} {NETWORK_NAME}\")\n",
    "\n",
    "# Print configuration README before (possible) training\n",
    "print(readme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1647955905819,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "yaknOjT38cZS"
   },
   "outputs": [],
   "source": [
    "# ################################################################\n",
    "# Predictions & export\n",
    "#\n",
    "# Here, the network is fed with the given input files. Resulting\n",
    "# predictions are exported as TIF files.\n",
    "# ################################################################\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from PIL import Image\n",
    "\n",
    "def evaluate_predictions(\n",
    "    input: np.ndarray,\n",
    "    nc: int,\n",
    "    f_weights: str,\n",
    "    optimizer: tf.keras.optimizers.Optimizer,\n",
    "    model_builder: typing.Callable,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Takes an input image, patches it into smaller patches and feeds the FCN\n",
    "    with each of the patches. The output samples are patches of the predicted\n",
    "    classification. These patches are combined into one large image, that can\n",
    "    be compared with the classified image of the corresponding input data.\n",
    "\n",
    "    :param input: test image to evaluate\n",
    "    :param nc: Number of classes/labels\n",
    "    :param f_weights: File path to the corresponding weights file\n",
    "    :param optimizer: Optimizer for the network\n",
    "    :param model_build: method to create the model\n",
    "    :return: 2D ndarray of the predicted labels\n",
    "    \"\"\"\n",
    "    x, y, bands = input.shape\n",
    "\n",
    "    # Build model and load model weights\n",
    "    model = model_builder(x, y, bands, nc)\n",
    "    # model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')\n",
    "    model.compile(optimizer=OPTIMIZER, loss=focal_tversky_loss, metrics='accuracy')\n",
    "    model.load_weights(f_weights)\n",
    "\n",
    "    # Predict field boundaries in network\n",
    "    # Increase dimension to perform batch prediction\n",
    "    input = np.expand_dims(input, 0)\n",
    "    prediction = model.predict(input)[0]\n",
    "    # Map highest score onto label\n",
    "    # prediction = np.argmax(prediction, axis=2) + 1\n",
    "    return prediction[:,:,1]\n",
    "\n",
    "def export_array(labels: np.ndarray, filename: str):\n",
    "    \"\"\"Maps labels onto the colors black & white and exports the resulting image\n",
    "    as a file with the given file.\n",
    "\n",
    "    :param labels: 2D array of labels per pixel\n",
    "    :param filename: File name of the new file\n",
    "    \"\"\"\n",
    "    x, y = labels.shape\n",
    "\n",
    "    img = np.zeros((x, y, 3), dtype=np.uint8)\n",
    "\n",
    "    for i in range(img.shape[2]):\n",
    "        img[:, :, i] = np.where(labels[:, :] == 2, 255, 0)\n",
    "\n",
    "    Image.fromarray(img).save(filename)\n",
    "    #Image.fromarray(img).save()\n",
    "    #pyplot.imsave(filename, Image.fromarray(img))\n",
    "\n",
    "def export_geotiff(labels: np.ndarray, geoTrans, geoProj, filename: str):\n",
    "    \"\"\"Maps labels onto the colors black & white and exports the resulting image\n",
    "    as a file with the given file.\n",
    "\n",
    "    :param labels: 2D array of labels per pixel\n",
    "    :param filename: File name of the new file\n",
    "    \"\"\"\n",
    "    x, y = labels.shape\n",
    "    # labels[:, :] = np.where(labels[:, :] == 2, 65535, 0)\n",
    "    labels[:, :] *= 65535\n",
    "    # import matplotlib.pylab as plt\n",
    "    # plt.hist(labels.reshape(x*y)); plt.show()\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    outData = driver.Create(filename, x, y, 3, gdal.GDT_UInt16)\n",
    "\n",
    "    # Write metadata\n",
    "    outData.SetGeoTransform(geoTrans)\n",
    "    outData.SetProjection(geoProj)\n",
    "\n",
    "    # Write raster data sets\n",
    "    for i in range(3):\n",
    "      outData.GetRasterBand(i+1).WriteArray(labels)\n",
    "    outData.FlushCache()\n",
    "    outData = None     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35790,
     "status": "ok",
     "timestamp": 1647955941605,
     "user": {
      "displayName": "Fan Xinyan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhkJp63mq5E6WGkjbTtP8l2Ab_NUuAkRuzni9NliA=s64",
      "userId": "17970603424071756767"
     },
     "user_tz": -60
    },
    "id": "iqWLGyUIJjm4",
    "outputId": "b8b6119d-5d95-4d8e-e66c-d46f2ddfcb88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/original/Vietnam/Prediction_UNet5/prediction_vietnam_24.tif\n",
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/original/Vietnam/Prediction_UNet5/prediction_vietnam_23.tif\n",
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/original/Vietnam/Prediction_UNet5/prediction_vietnam_20.tif\n",
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/original/Vietnam/Prediction_UNet5/prediction_vietnam_27.tif\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f451028f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f451028f040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/original/Vietnam/Prediction_UNet5/prediction_vietnam_26.tif\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f44eb79b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f44eb79b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported prediction /home/jovyan/private/Agricultural_Field_Boundary/original/Vietnam/Prediction_UNet5/prediction_vietnam_21.tif\n"
     ]
    }
   ],
   "source": [
    "# ################################################################\n",
    "# Predict images and store as TIF\n",
    "# \n",
    "# This code block will iterate through the included folders and\n",
    "# performs predictions on the satellite image tiles. The resulting\n",
    "# images are mapped onto black & white and then exported as TIF\n",
    "# files\n",
    "# ################################################################\n",
    "\n",
    "import pathlib\n",
    "\n",
    "\n",
    "keys_per_province = dict()\n",
    "\n",
    "for f in INCLUDE_FOLDERS:\n",
    "    keys_per_province[f] = [k for k in x_dict.keys() if k[0].lower() == f.lower()]\n",
    "\n",
    "\n",
    "for f, keys in keys_per_province.items():\n",
    "    for k in keys:\n",
    "        x = x_dict[k]\n",
    "\n",
    "        (_, _, f_weights, _) = get_file_names(NETWORK_UUID, NETWORK_NAME)\n",
    "\n",
    "        try:\n",
    "            img = evaluate_predictions(\n",
    "                x,\n",
    "                NUMBER_CLASSES,\n",
    "                f_weights,\n",
    "                OPTIMIZER,\n",
    "                model_builder,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to predict image of size {x.shape[0]}x{x.shape[1]}\")\n",
    "            continue\n",
    "\n",
    "        # Build directory name\n",
    "        fname = DATA_PATH\n",
    "        fname += f\"{f}/\"\n",
    "        fname += f\"Prediction_{NETWORK_NAME}/\"\n",
    "\n",
    "        # Create directory\n",
    "        pathlib.Path(fname).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # build filename\n",
    "        fname += f\"prediction_{k[0]}_{k[1]}\"\n",
    "        fname += \".tif\"\n",
    "\n",
    "        # export_array(img, fname)\n",
    "        export_geotiff(img, geoTrans[k],geoProj[k],fname)\n",
    "        print(f\"Exported prediction {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "network-prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
